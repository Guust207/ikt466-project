{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Architechture/CovNets\n",
    "\n",
    "Example for a 32 x 32 x 3 image\n",
    "- **Input layers:** The layer that gives us the input to our model. Holds raw input of the image at the dimensions used above.\n",
    "- **Convolutional Layers:** Extract features from the input dataset. It applies a set of learnable filters known as the kernels to the input images. Filters/kernels are smaller matrices (2x2 to 5x5 shape). Goes over the input image data and computes the dot product between kernel weight and the corresponding input image patch. Out from this layer is **feature maps**. If we use 12 filters, the output volume for this layer would be 32 x 32 x 12.\n",
    "- **Activation Layer:** Adding a activation function to the output of the preceding layer, the activation layers add nonlinearity to the network. It will apply an element-wise activation function to the output of the convolution layer. Examples: RELU, Tanh, Leaky...\n",
    "- **Pooling layer:** This layer is periodically inserted i the covnets and its main function is to reduce the size of volume which makes the computation fast, reduces memory and also preventing overfitting.\n",
    "- Two types:\n",
    "    - Max pooling\n",
    "    - Average pooling\n",
    "- If we use max pool with 2 x 2 filters and stride 2 (moving the filter 2 pixels at the time), the result volume would be in the dimensions of 16x16x12\n",
    "- **Flattening:** The resulting feature maps are flattened into a one-dimensional vector after the convolution and pooling layer so they can be passed into a completely linked layer for categorization or regression.\n",
    "- **Fully Connected Layers:** It takes the input from the previous layer and computes the final classification or regression task.\n",
    "- **Output Layer:** The output from the fully connected layers is then fed into a logistic function for classification tasks like sigmoid or softmax which converts the output of each class into the probability score of each class.\n",
    "\n",
    "Sources:\n",
    "- https://www.geeksforgeeks.org/machine-learning/introduction-convolution-neural-network/\n",
    "- https://www.geeksforgeeks.org/machine-learning/audio-recognition-in-tensorflow/\n",
    "\n",
    "\n"
   ],
   "id": "a1e8e93a2371ae6a"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-10T14:58:34.812074Z",
     "start_time": "2025-11-10T14:58:34.808280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pathlib\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report"
   ],
   "id": "87e784c2c87462ec",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T14:58:35.175639Z",
     "start_time": "2025-11-10T14:58:35.126178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# https://www.geeksforgeeks.org/machine-learning/audio-recognition-in-tensorflow/\n",
    "def model_architecture(input_shape, num_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=input_shape),\n",
    "\n",
    "        tf.keras.layers.Resizing(224, 224),\n",
    "        tf.keras.layers.Normalization(),\n",
    "\n",
    "        tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        tf.keras.layers.Flatten(),\n",
    "\n",
    "        #Dense layer\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "        #Softmax layer\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "    ])\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "print(\"Input shape:\", input_shape)\n",
    "num_labels = len(label_names)\n",
    "\n",
    "model = model_architecture(input_shape, num_classes)\n"
   ],
   "id": "82ef6b30955ff1a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (224, 224, 3)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'label_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 29\u001B[39m\n\u001B[32m     27\u001B[39m input_shape = (\u001B[32m224\u001B[39m, \u001B[32m224\u001B[39m, \u001B[32m3\u001B[39m)\n\u001B[32m     28\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mInput shape:\u001B[39m\u001B[33m\"\u001B[39m, input_shape)\n\u001B[32m---> \u001B[39m\u001B[32m29\u001B[39m num_labels = \u001B[38;5;28mlen\u001B[39m(\u001B[43mlabel_names\u001B[49m)\n\u001B[32m     31\u001B[39m model = model_architecture(input_shape, num_classes)\n",
      "\u001B[31mNameError\u001B[39m: name 'label_names' is not defined"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4f69d230f097963e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
